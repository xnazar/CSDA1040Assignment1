---
title: 'CSDA 1040: Assignment 1 - Group 4'
author: "Jose German, Anjana Pradeep Kumar, Anupama Radhakrishnan Kowsalya, Xenel Nazar"
date: "6/14/2020"
output: html_document
---
# 1.0 Abstract

# 2.0 Introduction
Books remain an important medium in today's society. In 2018, over 675 million print books were sold in the U.S. and book stores bring in almost 10 million dollars per year (https://www.statista.com/topics/1177/book-market/). While, in Canada, 54 million books accounting to 1.1 billion dollars in retail value, were sold in 2018 (http://www.ontariocreates.ca/collaboration/research_and_industry_information/industry_profiles/Book_Industry_Profile.htm#footnote-2). 

Consumption of books remains relevant, as 74% of U.S. consumers have noted that they have consumed at least one book in the past year, and 98% of readers say pleasure is their main reason for reading books (https://www.statista.com/topics/1177/book-market/).




# 3.0 Background

# 4.0 Objectives
The objective is to find an effective recommender system to recommend the next book they should read, based on their inputs. 

# 5.0 Data Understanding

## 5.1 About the Data

The data is a crawl by Cai-Nicolas Ziegler  of the Department of Computer Science from the University of Freiburg on the BookCrossing community for a four week period in August to September 2004 (http://www2.informatik.uni-freiburg.de/~cziegler/BX/). 

The BookCrossing community releases "books into the wild for a stranger to find, or via controlled release to another BookCrossing member" (https://www.bookcrossing.com/?). The data is a compilation of anonymized users with their locations, their explicit & implicit ratings, and information about the books they have read. 

The data is compiled into three distinct csv files on User data ("BX-Users.csv"), Books ("BX-Books.csv"), and Ratings ("BX-Book-Ratings.csv")

Each csv file contains various attributes such as:

Users:
- User-Id: Represents each anonymized user
- Location: The user's location
- Age: The user's age

Books:
- ISBN: International Standard Book Number or unique identifier for each book. (https://www.isbn-international.org/content/what-isbn)
- Book-Title: Title of the book
- Book-Author: The book's author
- Year-of-Publication: Year when the book was published
- Publisher: The book's publisher
- Image-URL-S: Small cover image, linked to the Amazon website
- Image-URL-M: Medium cover image, linked to the Amazon website
- Image-URL-L: Large cover image, linked to the Amazon website

Ratings:
- User-Id: Represents each anonymized user
- ISBN: International Standard Book Number or unique identifier for each book. (https://www.isbn-international.org/content/what-isbn)
- Book-Rating: Either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0.

## 5.2	Import Packages
```{r}
knitr::opts_chunk$set(echo=TRUE)
```

```{r}
#Path setup
#path<- "C:/RProjects/bookcrossing"
#setwd(path)
getwd()
```

```{r}
library(data.table)
library(plotly)
library(ggplot2)
library(RColorBrewer)
library(stringr)
library(plyr)
library(tidyr)
library(dplyr)
library(rcompanion)
library(e1071)
library(outliers)
library(recommenderlab)
```


## 5.3	Import Data
```{r}
# Import CSV Files

# Import Books CSV
books <- read.csv("BX-Books.csv", header = TRUE, sep = ";", quote="", stringsAsFactors = FALSE, col.names = c("ISBN", "Book_Title", "Book_Author", "Year_of_Publication", "Publisher", "Image_S", "Image_M", "Image_L"))

# Import Users CSV
users=read.csv("BX-Users.csv", header = TRUE, sep = ";", quote="", stringsAsFactors = FALSE, col.names = c("UserId","Location","Age"))

# Import Ratings CSV
ratings=read.csv("BX-Book-Ratings.csv", header = TRUE, sep=";", quote="", stringsAsFactors = FALSE, col.names = c("UserId","ISBN","Rating"))
```

# 6.0	Data Exploration and Preparation

## 6.1 Initial Data cleanup

We first need to remove quotes from the data.
```{r}
# Function to remove quotes from dataframes
clean <- colwise(function(ttt) str_replace_all(ttt, '\"', ""))
```

```{r}
# Apply clean function
books[] <- clean(books)
ratings[] <- clean(ratings)
users[] <- clean(users)
```

We also neeed to ensure certain columns as numeric. 
```{r}
# Convert Certain Columns as Numeric

# Convert UserID and Age in Users Dataframe
users$UserId<-as.numeric(users$UserId)
users$Age<-as.numeric(users$Age)

# Convert Year of Publication in Books Dataframe
books$Year_of_Publication<-as.numeric(books$Year_of_Publication)

# Convert UserId and Rating in Ratings Dataframe
ratings$UserId<-as.numeric(ratings$UserId)
ratings$Rating<-as.numeric(ratings$Rating)
```

Note: We are not converting the ISBN columns as numeric as they may contain the Roman Numeral "X" instead of the number 10 (https://www.isbn.org/faqs_general_questions#isbn_faq5).


We are also removing image links from the books dataframe as it will not be pertinent for later analysis. This may be included later during deployment or future iterations of the recommender system.
```{r}
# Remove Columns "Image_S", "Image_M", "Image_L" from books dataframe
books<-books[-c(6,7,8)]
```

## 6.2 Verify Data Types

```{r}
# Data Types under books Dataframe
str (books)
```

```{r}
# Data Types for users Dataframe
str (users)
```

```{r}
# Data Types for ratings Dataframe
str(ratings)
```

## 6.3 Check for Missing Values

```{r}
# Check books Dataframe
sum (is.na(books))
```

```{r}
# Check users Dataframe
sum(is.na(users))
```

```{r}
# Check ratings Dataframe
sum(is.na(ratings))
```

## 6.4 Check for Duplicates
```{r}
# Check Duplicates under books Dataframe
anyDuplicated(books)
```
Results:

```{r}
# Check Duplicates under users Dataframe
anyDuplicated(users)
```
Results:

```{r}
# Check Duplicates under ratings Dataframe
anyDuplicated(ratings)
```
Results: There are no duplicates under ratings

## 6.5 Summary of the Variables
```{r}
# Details of books Dataframe
summary (books)
```

```{r}
# Details of users Dataframe
summary (users)
```

```{r}
# Details of ratings Dataframe
summary (ratings)
```

## 6.6 Simple Statistics
```{r}
##
```

## 6.7 Replace NULL Values with NA
```{r}
# Replace NULL values with NA
users_df <-users %>% replace(.=="NULL", NA)
books_df <-books %>% replace(.=="NULL", NA)
ratings_df<-ratings %>% replace(.=="NULL", NA)
```

## 6.8 Remove rows with NA
```{r}
# Remove rows with NA
users_df<-users_df %>% drop_na(UserId)
users_df<-users_df %>% drop_na(Location)
books_df<-na.omit(books_df)
```

## 6.9 Filter out rows with webaddresses under ISBN

There was likely an error during the initial compilation of the web crawl, resulting in some links showing under ISBN instances. These web addresses need to be removed from our data to help our analysis. 
```{r}
# Filter out rows containing web addresses under ISBN (e.g. "http")
books_df<-books_df[!grepl("http", books_df$ISBN),]
```

## 6.10 Further cleanup
```{r}
# Replace ages less than 10 and greater than 100
users_df$Age[users_df$Age > 100] <- NA
users_df$Age[users_df$Age < 10] <- NA
```

```{r}
# Replace missing age with mean
ageMean = trunc(mean(users_df$Age, na.rm = TRUE))
users_df$Age[is.na(users_df$Age)] <- ageMean
```

```{r}
# Replace year =0 and NA  with mean
yearMean = trunc(mean(books_df$Year_of_Publication, na.rm = TRUE))
books_df$Year_of_Publication[books_df$Year_of_Publication ==0] <- NA
books_df$Year_of_Publication[is.na(books_df$Year_of_Publication)] <- yearMean
```

## 6.11 Merge dataframes
```{r}
# Merge ratings and books dataframes to "ratings_books" dataframe
ratings_books<-left_join(ratings_df,books_df,by="ISBN")
```

```{r}
# Merge ratings_books and users dataframes to "ratings_books_users" dataframe"
ratings_books_users<-left_join(ratings_books,users_df,by="UserId")
```

## 6.12 remove NAs from dataframe
```{r}
# Remove NAs from dataframe
ratings_books_users<-na.omit(ratings_books_users)
```

## 6.13 Subset dataframe to Explicit and Implicit ratings
```{r}
# Subset dataframe to Explicit and Implicit Ratings
ratings_explicit<-subset(ratings_books_users,ratings_books_users$Rating>0)
ratings_implicit<-subset(ratings_books_users,ratings_books_users$Rating==0)
```

```{r}
# Popular books
most_read_books<-ratings_books_users%>%
  group_by(ISBN,Book_Title,Book_Author,Publisher)%>%
  summarize(num_ISBN=n())%>%
  filter(num_ISBN>200)%>%
  arrange(-num_ISBN)%>%
  select(ISBN,Book_Title,Book_Author,Publisher)%>%
  head(10)

# Save to list
poplist<-most_read_books%>%
  select(ISBN,Book_Title,Book_Author,Publisher)
```

```{r}
# Plot Popular books
bp<- ggplot(most_read_books, aes(x="Popular Books", y=num_ISBN, fill=title))+
  geom_bar(width = 1, stat = "identity")

bp + scale_fill_brewer(palette="Dark2")+theme_minimal()
```


```{r}
# Top Rated books
top_rated_books<-ratings_explicit%>%
  group_by(ISBN,Book_Title,Book_Author,Publisher)%>%
  filter(Rating>7)%>%
  summarize(num_ISBN=n())%>%
  filter(num_ISBN>50)%>%
  arrange(-num_ISBN)%>%
  select(ISBN,Book_Title,Book_Author,Publisher)%>%
  head(10)

# Save to list
topratelist<-top_rated_books%>%
  select(ISBN,Book_Title,Book_Author,Publisher)
```
```{r}
pie<- ggplot(top_rated_books, aes(x="Top rated books", y=num_ISBN, fill=title))+
  geom_bar(width = 1, stat = "identity")

pie + coord_polar("y", start=0)
```


```{r}
# Subset data to users who have rated 50 or more books
rating_matrix_long<-ratings_explicit%>%
  add_count(UserId)%>%
  dplyr::filter(n>50)%>%
  select(ISBN,UserId,Rating)%>%
  arrange(UserId)
```


```{r}
# Narrow down to only books that were rated 50 or more 
rating_matrix_long<-rating_matrix_long%>%
  add_count(ISBN)%>%
  dplyr::filter(n>50)%>%
  select(ISBN,UserId,Rating)%>%
  arrange(ISBN)
```

```{r}
# Save to list
booklist<-rating_matrix_long%>%
  left_join(books_df,by="ISBN")%>%
  select(Book_Title)%>%
  unique()
```


```{r}
# User-Book Rating matrix
rating_matrix<-rating_matrix_long%>%pivot_wider(names_from = ISBN,values_from=Rating,values_fill=0)
```

```{r}
# Check Age Distribution

table(users_df$Age)
barplot(table(users_df$Age),main="Age Distribution")
```

```{r}
# Replot and check
table(users_df$Age)
barplot(table(users_df$Age),main="Age Distribution")

```

```{r}
# Rating Distribution, Summary, Statistics and Normalization

summary(ratings_explicit)
range(ratings_explicit$Rating)

rating_dist = ratings_explicit$Rating
plotNormalHistogram(rating_dist)

print(skewness(ratings_explicit$Rating))# Left skewed by -0.6613279
```

```{r}
# Identify Outliers
outlier(ratings_explicit$Rating)
ratings_norm<-subset(ratings_explicit,ratings_explicit$Rating>3)

print(skewness(ratings_norm$Rating)) # skewness after  -0.3522745
```

```{r}
# Normalising using log transformation
rating_log_norm = ratings_norm$Rating
ratings_norm$Rating<-log(ratings_norm$Rating)
plotNormalHistogram(rating_log_norm)
```

```{r}
# matrix with users rated more than 50 

rating_matrix_long<-ratings_norm%>%
  add_count(UserId)%>%
  dplyr::filter(n>50)%>%
  select(ISBN,UserId,Rating)%>%
  arrange(UserId)
```

```{r}
# matrix with books rated more than 50 

rating_matrix_long<-rating_matrix_long%>%
  add_count(ISBN)%>%
  dplyr::filter(n>50)%>%
  select(ISBN,UserId,Rating)%>%
  arrange(ISBN)
```

```{r}
booklist<-rating_matrix_long%>%
  left_join(books_df,by="ISBN")%>%
  select(Book_Title)%>%
  unique()
```

```{r}
# User-Book Rating matrix
rating_matrix<-rating_matrix_long%>%pivot_wider(names_from = ISBN,values_from=Rating)
```

```{r}
# Removing userid from rating matrix
rating_matrix = as.matrix(rating_matrix[,-1])
```

```{r}
# Real matrix
object.size(rating_matrix)
rating_matrix = as(rating_matrix, "realRatingMatrix")
object.size(rating_matrix)
```

```{r}
#Normalize the ratings matrix
#rating_matrix = normalize(rating_matrix)
```

```{r}
ratingmodel = Recommender(rating_matrix, method = "UBCF", param=list(method="Cosine",nn=10)) 
```

```{r}
# Predictions
Top_5_pred = predict(ratingmodel, rating_matrix[1], n=5)
Top_5_List = as(Top_5_pred, "list")
```

```{r}
# Recommended predictions for a user based on previous ratings
recomdf=data.frame(Top_5_List)
colnames(recomdf)="ISBN"
bookrecomdf<-left_join(recomdf,books_df,by="ISBN")%>%
  select(Book_Title)%>%
  print()
```


```{r}
books_df_year<-books_df%>%
  group_by(Year_of_Publication)%>%
  summarise(counts = n())

ggplot(books_df_year, aes(x=Year_of_Publication, y=counts)) +geom_point()
```


```{r}
# Split the Location column in ratings_book_user into City, Prov, Country
# Creates new dataframe: ratings_book_user_loc

ratings_books_users_loc <- separate(data = ratings_books_users, col = Location, into = c("City", "Prov", "Country"), sep = "\\,")
```

```{r}
# Split the Location column in ratings_book_user into City, Prov, Country
# Creates new dataframe: ratings_book_user_loc

ratings_explicit_loc <- separate(data = ratings_explicit, col = Location, into = c("City", "Prov", "Country"), sep = "\\,")
```

# 7.0 Modeling

# 8.0 Conclusions and Recommendations

## 8.1 Conclusions

## 8.2 Recomendations

Additional info could additionally benefit the recomender system, to help narrow down books the users may like data on the books' genre, language, number of pages, etc.

# 9.0 Deployment

The underlying code of this markdown report and the shiny app, can be found on [Github](https://github.com/xnazar/CSDA1040Assignment1)

# 10.0 Bibliography

http://www2.informatik.uni-freiburg.de/~cziegler/BX/

https://www.isbn-international.org/content/what-isbn

https://www.isbn.org/faqs_general_questions#isbn_faq5

https://www.statista.com/topics/1177/book-market/

http://www.ontariocreates.ca/collaboration/research_and_industry_information/industry_profiles/Book_Industry_Profile.htm#footnote-2

